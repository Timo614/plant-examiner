{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXB_ebckKKL_"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVyQOaCzKKMC"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRMgmMLtKKMC"
      },
      "source": [
        "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
        "\n",
        "Read our **[Gemma 3N Guide](https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGMWlrRdzwgf"
      },
      "source": [
        "### Unsloth\n",
        "\n",
        "`FastModel` supports loading nearly any model now! This includes Vision and Text models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xbb0cuLzwgf",
        "outputId": "f37d092a-8341-4b4a-a042-0185013b3125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/unsloth/unsloth/__init__.py:174: UserWarning: Unsloth: Running `ldconfig /usr/lib64-nvidia` to link CUDA.\n",
            "  warnings.warn(\n",
            "/app/unsloth/unsloth/__init__.py:208: UserWarning: Unsloth: CUDA is not linked properly.\n",
            "Try running `python -m bitsandbytes` then `python -m xformers.info`\n",
            "We tried running `ldconfig /usr/lib64-nvidia` ourselves, but it didn't work.\n",
            "You need to run in your terminal `sudo ldconfig /usr/lib64-nvidia` yourself, then import Unsloth.\n",
            "Also try `sudo ldconfig /usr/local/cuda-xx.x` - find the latest cuda version.\n",
            "Unsloth will still run for now, but maybe it might crash - let's hope it works!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/unsloth/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/unsloth/venv/lib/python3.12/site-packages/unsloth_zoo/gradient_checkpointing.py:339: UserWarning: expandable_segments not supported on this platform (Triggered internally at /pytorch/c10/hip/HIPAllocatorConfig.h:36.)\n",
            "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.7.5: Fast Gemma3N patching. Transformers: 4.53.2.\n",
            "   \\\\   /|    AMD Radeon PRO W7900. Num GPUs = 1. Max memory: 44.984 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0.dev20250718+rocm6.3. CUDA: 11.0. CUDA Toolkit: None. Triton: 3.1.0+cf34004b8a\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Gemma3N does not support SDPA - switching to eager!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.52s/it]\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastModel\n",
        "import torch\n",
        "\n",
        "torch._dynamo.config.cache_size_limit = 32\n",
        "\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3n-E2B-it-unsloth-bnb-4bit\",\n",
        "    # Pretrained models\n",
        "    \"unsloth/gemma-3n-E4B-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3n-E2B-unsloth-bnb-4bit\",\n",
        "\n",
        "    # Other Gemma 3 quants\n",
        "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastModel.from_pretrained(\n",
        "    model_name = \"unsloth/gemma-3n-E4B-it\",\n",
        "    dtype = None, # None for auto detection\n",
        "    max_seq_length = 1024, # Choose any for long context!\n",
        "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        "    # token = \"hf_...\", # use one if using gated models\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixr4dyTHVIcI"
      },
      "source": [
        "# Gemma 3N can process Text, Vision and Audio!\n",
        "\n",
        "Let's first experience how Gemma 3N can handle multimodal inputs. We use Gemma 3N's recommended settings of `temperature = 1.0, top_p = 0.95, top_k = 64`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsfUPU-oVQYu"
      },
      "outputs": [],
      "source": [
        "from transformers import TextStreamer\n",
        "import gc\n",
        "# Helper function for inference\n",
        "def do_gemma_3n_inference(model, tokenizer, messages, max_new_tokens=128):\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # generate returns the full sequence of IDs because we dropped `streamer=‚Ä¶`\n",
        "    out_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=1.15,\n",
        "        top_p=0.95,\n",
        "        top_k=64,\n",
        "    )\n",
        "\n",
        "    # slice off the prompt part and decode\n",
        "    gen_ids = out_ids[0][inputs[\"input_ids\"].shape[-1]:]\n",
        "    text = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "    del inputs\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2-ddk0CWeTA"
      },
      "source": [
        "# Gemma 3N can see images!\n",
        "\n",
        "<img src=\"https://files.worldwildlife.org/wwfcmsprod/images/Sloth_Sitting_iStock_3_12_2014/story_full_width/8l7pbjmj29_iStock_000011145477Large_mini__1_.jpg\" alt=\"Alt text\" height=\"256\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jGeSb9bWe0k",
        "outputId": "32a621ab-9770-46cd-cb91-6b6cb1af3a97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This adorable animal is a **sloth**, and it has featured in several films! Here are some notable ones:\\n\\n* **Zootopia (2016):** The character Judy Hopps has a playful interaction with a sloth named Bellwether.\\n* **The Jungle Book 2 (2003):** A sloth named Costa helps Mowgli and Baloo on their journey.\\n* **Madagascar (2005):** Sloths appear in the background and add to the vibrant wildlife of the film.\\n* **Kung Fu Panda 3 (2016):** The sloth Shen has a memorable and important role in the movie. \\n\\nSloths are popular characters in animation and live-action films due to their unique and endearing nature! \\n\\n\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "sloth_link = \"https://files.worldwildlife.org/wwfcmsprod/images/Sloth_Sitting_iStock_3_12_2014/story_full_width/8l7pbjmj29_iStock_000011145477Large_mini__1_.jpg\"\n",
        "\n",
        "messages = [{\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": [\n",
        "        { \"type\": \"image\", \"image\" : sloth_link },\n",
        "        { \"type\": \"text\",  \"text\" : \"Which films does this animal feature in?\" }\n",
        "    ]\n",
        "}]\n",
        "# You might have to wait 1 minute for Unsloth's auto compiler\n",
        "do_gemma_3n_inference(model, tokenizer = tokenizer, messages = messages, max_new_tokens = 256)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv, time\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ------------------------------------------------------------------ CONFIG\n",
        "SLEEP       = 0.05\n",
        "\n",
        "TARGET_LANGS = [\n",
        "    \"Chinese\",\"Hindi\",\"Spanish\",\"Arabic\",\"French\",\"Bengali\",\"Portuguese\",\n",
        "    \"Russian\",\"Indonesian\",\"Urdu\",\"German\",\"Japanese\",\"Nigerian Pidgin\",\n",
        "    \"Marathi\",\"Vietnamese\",\"Telugu\",\"Hausa\",\"Turkish\",\"Swahili\",\"Tagalog\",\n",
        "    \"Tamil\",\"Korean\",\"Thai\",\"Javanese\",\"Italian\",\"Hebrew\"\n",
        "]\n",
        "\n",
        "SRC  = Path(\"./plant_state_descriptions.csv\")\n",
        "DEST = Path(\"./plant_state_descriptions_output.csv\")\n",
        "\n",
        "# ------------------------------------------------------------- HELPERS\n",
        "def translate(text: str, language: str) -> str:\n",
        "    prompt = f\"Translate this to {language} (only return translated text no explanations): {text}\"\n",
        "    out = do_gemma_3n_inference(\n",
        "        model,\n",
        "        tokenizer = tokenizer,\n",
        "        messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}],\n",
        "        max_new_tokens=512\n",
        "    )\n",
        "    out = out if isinstance(out, str) else str(out)\n",
        "    return out\n",
        "\n",
        "# -------------------------------------------------------------- MAIN\n",
        "with SRC.open(newline=\"\", encoding=\"utf-8\") as fin:\n",
        "    rows = [r for r in csv.reader(fin)][1:]        # skip header\n",
        "english_rows = [r for r in rows if r[2] == \"English\"]\n",
        "\n",
        "total = len(english_rows) * (1 + len(TARGET_LANGS))\n",
        "with DEST.open(\"w\", newline=\"\", encoding=\"utf-8\") as fout, tqdm(total=total, desc=\"Rows\") as bar:\n",
        "    w = csv.writer(fout)\n",
        "    w.writerow([\"Plant\", \"State\", \"Language\", \"Text\"])\n",
        "\n",
        "    for plant, state, lang, text in english_rows:\n",
        "        w.writerow([plant, state, \"English\", text]);    bar.update(1)\n",
        "\n",
        "        for tgt in TARGET_LANGS:\n",
        "            translated = translate(text, tgt)\n",
        "            w.writerow([plant, state, tgt, translated]); bar.update(1)\n",
        "            time.sleep(SLEEP)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DKEOHpfdm8q",
        "outputId": "8bb454bf-1aaf-4c7f-f762-be106d347423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5130/5130 [18:40:28<00:00, 13.11s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iGPh66zJeEJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}